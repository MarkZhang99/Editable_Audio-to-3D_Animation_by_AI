{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21f5289-0e89-4019-ac76-cbf572c7aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5727214/.pyenv/versions/anaconda3-2024.06-1/envs/emotalk/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample loaded:\n",
      "audio: <class 'torch.Tensor'>, shape: torch.Size([67925])\n",
      "blendshape: <class 'torch.Tensor'>, shape: torch.Size([127, 52])\n",
      "level: <class 'torch.Tensor'>, shape: torch.Size([])\n",
      "person: <class 'torch.Tensor'>, shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#测试 DummyDataset 是否能正确读取 .pt\n",
    "from train import DummyDataset\n",
    "\n",
    "# 尝试读取一个 .pt 数据样本\n",
    "dataset = DummyDataset(\"./data/RAVDESS/train\")  # or ./data_hdtf_train\n",
    "sample = dataset[0]  # 取第0个样本\n",
    "\n",
    "print(\"✅ Sample loaded:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape if hasattr(v, 'shape') else v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0c523-b189-4fae-b68b-27c077b3b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import EmoTalk\n",
    "from loss_v0002 import EmoTalkLoss\n",
    "from train import DummyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# === 配置 ===\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "SAVE_PATH = 'emotalk_v1_retrained.pth'\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    feature_dim=1024,\n",
    "    bs_dim=52,\n",
    "    device=DEVICE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_seq_len=512,\n",
    "    period=20,\n",
    "    emotion_dim=256,\n",
    "    emo_gru_hidden=128,\n",
    "    emo_gru_layers=2,\n",
    "    transformer_layers=4,\n",
    "    transformer_heads=8,\n",
    "    transformer_dim=512,\n",
    "    num_emotions=2,   # 注意！模型中只用了2维情绪one-hot\n",
    "    num_person=24     # 模型中 one_hot_person 是 24维\n",
    ")\n",
    "\n",
    "# === 模型与优化器 ===\n",
    "model = EmoTalk(args).to(DEVICE)\n",
    "loss_fn = EmoTalkLoss(region_weighted=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# === 数据准备（你需要自己确保 DummyDataset 返回的格式正确）===\n",
    "train_dataset = DummyDataset('./data/RAVDESS/train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# === 开始训练 ===\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    logs_accum = {\"main\": 0, \"smooth\": 0, \"vel\": 0, \"total\": 0}\n",
    "\n",
    "    for raw in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # 构造模型输入\n",
    "        data = {\n",
    "            \"input12\": raw[\"audio\"].to(DEVICE),\n",
    "            \"input21\": raw[\"audio\"].to(DEVICE),\n",
    "            \"target11\": raw[\"blendshape\"].to(DEVICE),\n",
    "            \"target12\": raw[\"blendshape\"].to(DEVICE),\n",
    "            \"level\": raw[\"level\"].item(),\n",
    "            \"person\": raw[\"person\"].item()\n",
    "        }\n",
    "\n",
    "        output1, output2, _ = model(data)\n",
    "\n",
    "        loss1, logs1 = loss_fn(output1, data[\"target11\"])\n",
    "        loss2, logs2 = loss_fn(output2, data[\"target12\"])\n",
    "        loss = (loss1 + loss2) / 2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        for k in logs1:\n",
    "            logs_accum[k] += (logs1[k] + logs2[k]) / 2\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\n[Epoch {epoch+1}] Train Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  -> main: {logs_accum['main']:.4f} | smooth: {logs_accum['smooth']:.4f} | vel: {logs_accum['vel']:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    print(f\"✅ Model saved to {SAVE_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotalk (Python 3.8.8)",
   "language": "python",
   "name": "emotalk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
