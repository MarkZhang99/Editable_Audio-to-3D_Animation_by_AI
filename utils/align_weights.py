import os
import torch
from Emotalk_model_v0003 import EmoTalk  # ç¡®ä¿è¿™æ˜¯ä¿®æ”¹è¿‡ alias çš„æ–°ç‰ˆ
from types import SimpleNamespace

# â€”â€” 1. å’Œæ—§æ¨¡å‹ç”¨çš„ä¸€æ ·çš„ args â€”â€” #
args_v2 = SimpleNamespace(
    transformer_dim    = 512,
    transformer_heads  = 4,
    transformer_layers = 1,
    emo_gru_hidden     = 128,
    emo_gru_layers     = 2,
    num_emotions       = 2,
    num_person         = 24,
    max_seq_len        = 512,
    period             = 20,
    bs_dim             = 52,
    device             = 'cuda' if torch.cuda.is_available() else 'cpu',
    batch_size = 1
)

DEVICE = args_v2.device
OLD_CKPT = '/transfer/emotalk/EmoTalk_release-main/pretrain_model/EmoTalk.pth'
NEW_CKPT = 'aligned_v2_init.pth'

# â€”â€” 2. åŠ è½½æ—§æƒé‡å­—å…¸ â€”â€” #
old_state = torch.load(OLD_CKPT, map_location=DEVICE)

# â€”â€” 3. å®šä¹‰ key å‰ç¼€æ˜ å°„ â€”â€” #
prefix_map = {
    'audio_encoder_cont.':    'extractor.',       # Wav2Vec2Model
    'processor.':             'feature_extractor.',# feature extractor
    'audio_feature_map_cont.': 'extractor_proj.', # å†…å®¹æŠ•å°„
    'audio_feature_map_emo.':   'audio_feature_map_emo.', # æƒ…æ„ŸæŠ•å°„ï¼ˆåå­—ç›¸åŒï¼‰
    'audio_feature_map_emo2.':  'audio_feature_map_emo2.',# äºŒçº§æƒ…æ„ŸæŠ•å°„
    'transformer_decoder.':    'decoder.',         # TransformerDecoder
    'bs_map_r.':               'linear.'           # è¾“å‡ºçº¿æ€§å±‚
}

# â€”â€” 4. é‡å†™æ—§ state_dict key â€”â€” #
remapped_state = {}
for k, v in old_state.items():
    new_k = k
    for old_pf, new_pf in prefix_map.items():
        if k.startswith(old_pf):
            new_k = new_pf + k[len(old_pf):]
            break
    remapped_state[new_k] = v

# â€”â€” 5. å®ä¾‹åŒ–æ–°ç‰ˆå¹¶æ‹¿åˆ°å®ƒçš„ state_dict â€”â€” #
model_v2 = EmoTalk(args_v2).to(DEVICE)
new_state = model_v2.state_dict()

# â€”â€” 6. ç­›é€‰ shape åŒ¹é…çš„ tensor â€”â€” #
matched = {}
for k, v in remapped_state.items():
    if k in new_state and v.size() == new_state[k].size():
        matched[k] = v

print(f"ğŸ”‘ Matched keys:   {len(matched)}")
print(f"âŒ Old-only keys:  {len(old_state)-len(matched)}")
print(f"âŒ New-only keys:  {len(new_state)-len(matched)}")

# â€”â€” 7. åˆå¹¶ & åŠ è½½ â€”â€” #
new_state.update(matched)
info = model_v2.load_state_dict(new_state, strict=False)
print("â¡ï¸  Loaded with strict=False")
print("   missing_keys:", info.missing_keys)
print("   unexpected_keys:", info.unexpected_keys)

# â€”â€” 8. ä¿å­˜æ–°çš„ warm-start æ¨¡å‹ â€”â€” #
torch.save(model_v2.state_dict(), NEW_CKPT)
print(f"âœ… Saved aligned init model to {NEW_CKPT}")
